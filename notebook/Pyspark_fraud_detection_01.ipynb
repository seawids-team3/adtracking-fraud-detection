{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "print (pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rsandstroem.github.io/sparkdataframes.html\n",
    "https://medium.com/@naomi.fridman/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  100000\n",
      "root\n",
      " |-- ip: integer (nullable = true)\n",
      " |-- app: integer (nullable = true)\n",
      " |-- device: integer (nullable = true)\n",
      " |-- os: integer (nullable = true)\n",
      " |-- channel: integer (nullable = true)\n",
      " |-- click_time: timestamp (nullable = true)\n",
      " |-- attributed_time: timestamp (nullable = true)\n",
      " |-- is_attributed: integer (nullable = true)\n",
      "\n",
      "+------+---+------+---+-------+-------------------+---------------+-------------+\n",
      "|    ip|app|device| os|channel|         click_time|attributed_time|is_attributed|\n",
      "+------+---+------+---+-------+-------------------+---------------+-------------+\n",
      "| 87540| 12|     1| 13|    497|2017-11-07 09:30:38|           null|            0|\n",
      "|105560| 25|     1| 17|    259|2017-11-07 13:40:27|           null|            0|\n",
      "|101424| 12|     1| 19|    212|2017-11-07 18:05:24|           null|            0|\n",
      "| 94584| 13|     1| 13|    477|2017-11-07 04:58:08|           null|            0|\n",
      "| 68413| 12|     1|  1|    178|2017-11-09 09:00:09|           null|            0|\n",
      "| 93663|  3|     1| 17|    115|2017-11-09 01:22:13|           null|            0|\n",
      "| 17059|  1|     1| 17|    135|2017-11-09 01:17:58|           null|            0|\n",
      "|121505|  9|     1| 25|    442|2017-11-07 10:01:53|           null|            0|\n",
      "|192967|  2|     2| 22|    364|2017-11-08 09:35:17|           null|            0|\n",
      "|143636|  3|     1| 19|    135|2017-11-08 12:35:26|           null|            0|\n",
      "| 73839|  3|     1| 22|    489|2017-11-08 08:14:37|           null|            0|\n",
      "| 34812|  3|     1| 13|    489|2017-11-07 05:03:14|           null|            0|\n",
      "|114809|  3|     1| 22|    205|2017-11-09 10:24:23|           null|            0|\n",
      "|114220|  6|     1| 20|    125|2017-11-08 14:46:16|           null|            0|\n",
      "| 36150|  2|     1| 13|    205|2017-11-07 00:54:09|           null|            0|\n",
      "| 72116| 25|     2| 19|    259|2017-11-08 23:17:45|           null|            0|\n",
      "|  5314|  2|     1|  2|    477|2017-11-09 07:33:41|           null|            0|\n",
      "|106598|  3|     1| 20|    280|2017-11-09 03:44:35|           null|            0|\n",
      "| 72065| 20|     2| 90|    259|2017-11-06 23:14:08|           null|            0|\n",
      "| 37301| 14|     1| 13|    349|2017-11-06 20:07:00|           null|            0|\n",
      "+------+---+------+---+-------+-------------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "sdf = sqlContext.read.csv('train_sample.csv', header=True, inferSchema=True) # requires spark 2.0 or later\n",
    "print ('Number of rows: ' , sdf.count())\n",
    "sdf.printSchema()\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-------+-----------+\n",
      "|         click_time| time|weekday|weekdaytime|\n",
      "+-------------------+-----+-------+-----------+\n",
      "|2017-11-07 09:30:38|09:30|    Tue|    2 09:30|\n",
      "|2017-11-07 13:40:27|13:40|    Tue|    2 13:40|\n",
      "|2017-11-07 18:05:24|18:05|    Tue|    2 18:05|\n",
      "|2017-11-07 04:58:08|04:58|    Tue|    2 04:58|\n",
      "|2017-11-09 09:00:09|09:00|    Thu|    4 09:00|\n",
      "|2017-11-09 01:22:13|01:22|    Thu|    4 01:22|\n",
      "|2017-11-09 01:17:58|01:17|    Thu|    4 01:17|\n",
      "|2017-11-07 10:01:53|10:01|    Tue|    2 10:01|\n",
      "|2017-11-08 09:35:17|09:35|    Wed|    3 09:35|\n",
      "|2017-11-08 12:35:26|12:35|    Wed|    3 12:35|\n",
      "|2017-11-08 08:14:37|08:14|    Wed|    3 08:14|\n",
      "|2017-11-07 05:03:14|05:03|    Tue|    2 05:03|\n",
      "|2017-11-09 10:24:23|10:24|    Thu|    4 10:24|\n",
      "|2017-11-08 14:46:16|14:46|    Wed|    3 14:46|\n",
      "|2017-11-07 00:54:09|00:54|    Tue|    2 00:54|\n",
      "|2017-11-08 23:17:45|23:17|    Wed|    3 23:17|\n",
      "|2017-11-09 07:33:41|07:33|    Thu|    4 07:33|\n",
      "|2017-11-09 03:44:35|03:44|    Thu|    4 03:44|\n",
      "|2017-11-06 23:14:08|23:14|    Mon|    1 23:14|\n",
      "|2017-11-06 20:07:00|20:07|    Mon|    1 20:07|\n",
      "+-------------------+-----+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.select('click_time', date_format('click_time', 'HH:mm').alias('time'), date_format('click_time', 'E').alias('weekday'), date_format('click_time', 'u HH:mm').alias('weekdaytime')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "codemirror_mode": "text/x-ipython",
   "file_extension": ".py",
   "mimetype": "text/x-ipython",
   "name": "python",
   "pygments_lexer": "python",
   "version": "3.6.8\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
